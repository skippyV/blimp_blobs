%fit3Dlocation.m
% modified from calib.m by
% Jeremy Bredfeldt - Morgridge Institutes for Research
% Sept 2013

%Trying to derive the camera calibration matrices from first principles
%If we know the pose of the camera, then what are the camera matrices?
%With this, we can ROM check the calibrations generated by the calibration routines

%Then can we use these matrices to triangulate points properly in 3D, based on 2 camera poses?

%Place the origin in the south, west, floor level corner of the atrium
%Positive x = points east
%Positive y = points north
%Positive z = up
%Rotations: Cameras start pointing in positive z direction, and rotated from there
% Bottom of camera is pointing in neg y direction
% Use right hand rule for direction of rotation

function exyz = get3Dlocation(ccp,c1xy,c2xy)
%Atrium dimensions
%39624 mm in x direction
ax = 42610;
%10947 mm in y direction
ay = 8660;
%15240 mm in z direction
az = 15240;

%Camera sensor and lens
%Focal length = 4.2 mm
fx = 4.2;
fy = fx;
%Sensor = 4.54 mm X 3.42 mm
sx = 4.54/2;
sy = 3.42/2;
%Image size = 1280 X 720 pixels
ix = 1280;
iy = 720;

%These are in the world's reference frame, to actually get camera matrices, these must be inverted.
%--Translation--
%Camera 1 (west side)
% Cx1 = 0;
% Cy1 = ay/2; %centered in y dim
% Cz1 = az;
Cx1 = ccp(1);
Cy1 = ccp(2); %centered in y dim
Cz1 = ccp(3);

C1 = [Cx1; Cy1; Cz1];

%Camera 2 (east side)
% Cx2 = ax;
% Cy2 = ay/2;
% Cz2 = az;
Cx2 = ccp(4);
Cy2 = ccp(5);
Cz2 = ccp(6);

C2 = [Cx2; Cy2; Cz2];

%--Rotation--
%Camera 1
% thx1 = 0;
% thy1 = pi/1.5; %point 45 deg down
% thz1 = 0;
thx1 = ccp(7);
thy1 = ccp(8);
thz1 = ccp(9);
Rcx1 = [1 0 0; 0 cos(thx1) -sin(thx1); 0 sin(thx1) cos(thx1)];
Rcy1 = [cos(thy1) 0 sin(thy1); 0 1 0; -sin(thy1) 0 cos(thy1)];
Rcz1 = [cos(thz1) -sin(thz1) 0; sin(thz1) cos(thz1) 0; 0 0 1];
Rc1 = Rcx1*Rcy1*Rcz1;

%Camera 2
% thx2 = 0;
% thy2 = -pi/1.5; %point 45 deg down
% thz2 = pi;
thx2 = ccp(10);
thy2 = ccp(11);
thz2 = ccp(12);

Rcx2 = [1 0 0; 0 cos(thx2) -sin(thx2); 0 sin(thx2) cos(thx2)];
Rcy2 = [cos(thy2) 0 sin(thy2); 0 1 0; -sin(thy2) 0 cos(thy2)];
Rcz2 = [cos(thz2) -sin(thz2) 0; sin(thz2) cos(thz2) 0; 0 0 1];
Rc2 = Rcx2*Rcy2*Rcz2;

%Get the actual camera matrices (inverse of the previously written matrices):
R1 = Rc1';
R2 = Rc2';
t1 = -R1*C1; %origin in cam 1 ref frame
t2 = -R2*C2; %origin in cam 2 ref frame

%--Extrinsic--
E1 = [R1 t1];
E2 = [R2 t2];

%--Intrinsic--
%Assume no skew or translation, and fx and fy are same
%Assume both cameras are the same
K = [fx 0 0; 0 fy 0; 0 0 1];

%--Final Matrices--
P1 = K*E1;
P2 = K*E2;


%now triangulate to find the 3d location again, using the camera matrices
[nums,numc] = size(c1xy);

for i = 1:nums
    
    exyz(i,1:3) = triangulateJYB(P1,c1xy(i,:),P2,c2xy(i,:));
    
end

fprintf('P1 = np.array([[%f,%f,%f,%f],[%f,%f,%f,%f],{%f,%f,%f,%f]])\n', ...
        P1(1,1),P1(1,2),P1(1,3),P1(1,4),...
        P1(2,1),P1(2,2),P1(2,3),P1(2,4),...
        P1(3,1),P1(3,2),P1(3,3),P1(3,4));
fprintf('P2 = np.array([[%f,%f,%f,%f],[%f,%f,%f,%f],{%f,%f,%f,%f]])\n', ...
        P2(1,1),P2(1,2),P2(1,3),P2(1,4),...
        P2(2,1),P2(2,2),P2(2,3),P2(2,4),...
        P2(3,1),P2(3,2),P2(3,3),P2(3,4));    

end


